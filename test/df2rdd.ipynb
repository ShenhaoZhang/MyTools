{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/07 13:35:59 WARN Utils: Your hostname, Lamian resolves to a loopback address: 127.0.1.1; using 172.29.242.201 instead (on interface eth0)\n",
      "22/05/07 13:35:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/07 13:36:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.29.242.201:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3c49543ac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from plotnine.data import diamonds\n",
    "\n",
    "from apps.pyspark_tools import table_to_PandasDF_rdd,PandasDF_rdd_to_table\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('test')\n",
    "    .config(\"spark.executor.cores\",\"8\")\n",
    "    .config(\"spark.default.parallelism\",\"600\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|      cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+---------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|    Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|  Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|     Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|  Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "| 0.31|     Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
      "| 0.24|Very Good|    J|   VVS2| 62.8| 57.0|  336|3.94|3.96|2.48|\n",
      "| 0.24|Very Good|    I|   VVS1| 62.3| 57.0|  336|3.95|3.98|2.47|\n",
      "| 0.26|Very Good|    H|    SI1| 61.9| 55.0|  337|4.07|4.11|2.53|\n",
      "| 0.22|     Fair|    E|    VS2| 65.1| 61.0|  337|3.87|3.78|2.49|\n",
      "| 0.23|Very Good|    H|    VS1| 59.4| 61.0|  338| 4.0|4.05|2.39|\n",
      "|  0.3|     Good|    J|    SI1| 64.0| 55.0|  339|4.25|4.28|2.73|\n",
      "| 0.23|    Ideal|    J|    VS1| 62.8| 56.0|  340|3.93| 3.9|2.46|\n",
      "| 0.22|  Premium|    F|    SI1| 60.4| 61.0|  342|3.88|3.84|2.33|\n",
      "| 0.31|    Ideal|    J|    SI2| 62.2| 54.0|  344|4.35|4.37|2.71|\n",
      "|  0.2|  Premium|    E|    SI2| 60.2| 62.0|  345|3.79|3.75|2.27|\n",
      "| 0.32|  Premium|    E|     I1| 60.9| 58.0|  345|4.38|4.42|2.68|\n",
      "|  0.3|    Ideal|    I|    SI2| 62.0| 54.0|  348|4.31|4.34|2.68|\n",
      "|  0.3|     Good|    J|    SI1| 63.4| 54.0|  351|4.23|4.29| 2.7|\n",
      "|  0.3|     Good|    J|    SI1| 63.8| 56.0|  351|4.23|4.26|2.71|\n",
      "|  0.3|Very Good|    J|    SI1| 62.7| 59.0|  351|4.21|4.27|2.66|\n",
      "+-----+---------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "table = spark.createDataFrame(data=diamonds)\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = table_to_PandasDF_rdd(table=table,groupby_key=['color','clarity','cut'])\n",
    "rdd2 = rdd.mapValues(lambda dt:dt.assign(t=lambda dt2:dt2.x+dt2.y+dt2.z).drop(['color','clarity','cut'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carat', 'double'),\n",
       " ('depth', 'double'),\n",
       " ('table', 'double'),\n",
       " ('price', 'double'),\n",
       " ('x', 'double'),\n",
       " ('y', 'double'),\n",
       " ('z', 'double'),\n",
       " ('t', 'double')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PandasDF_rdd_to_table(rdd2).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b', 'c'), ('e', 'f', 'g')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list('abc')\n",
    "y = list('efg')\n",
    "\n",
    "t = zip(x,y)\n",
    "\n",
    "list(zip(*t))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cccc59590f452a708ebb547a6e7a40fed9211f3f85c18a6eda6775c9711ae99"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
